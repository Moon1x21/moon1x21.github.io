<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Robot programming lecture note | Jueun Mun</title> <meta name="author" content="Jueun Mun"> <meta name="description" content="Lecture note in 2022 fall Robot programming"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://moon1x21.github.io/blog/2022/Robot-Programming-lecture-note/"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Jueun </span>Mun</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Robot programming lecture note</h1> <p class="post-meta">December 10, 2022</p> <p class="post-tags"> <a href="/blog/2022"> <i class="fas fa-calendar fa-sm"></i> 2022 </a>   ·   <a href="/blog/category/school"> <i class="fas fa-tag fa-sm"></i> school</a>   </p> </header> <article class="post-content"> <h1 id="기말-정리-robot-programming">기말 정리 Robot Programming</h1> <h2 id="10-to-understand-slam">10. To understand SLAM</h2> <h3 id="localization">Localization</h3> <ul> <li>2장의 사진이 있을 때, 실제 location 이나 trajectory를 알 수 있는가? <ul> <li>실제 지도가 있고, 카메라 intrinsic parameter를 알면 알 수 있음.</li> </ul> </li> </ul> <h3 id="mapping">Mapping</h3> <ul> <li>2장의 사진을 통해 Map을 만들 수 있는가? <ul> <li>나의 정확한 pose와 카메라 intrinsic parameter를 알면 알 수 있음.</li> </ul> </li> </ul> <h3 id="feature-points">Feature points</h3> <ul> <li>Feature <ul> <li>Salient and repeatable points or regions</li> <li>Requirements <ul> <li>다른 이미지에서 같은 point가 비슷한 feature를 가지고 있어야함.</li> <li>뷰 포인트가 변경 되어도 동일한 위치에서 발견되어야 함.</li> <li>Rotation invariant</li> <li>Scale invariant</li> </ul> </li> </ul> </li> <li>Feature extraction method <ul> <li>Point-based methods <ul> <li>Harris Corner</li> <li>Fast</li> </ul> </li> <li>Blob-based methods <ul> <li>DOF(Different of Gaussian)</li> <li>LoG(Laplacian of Gaussian)</li> </ul> </li> <li>Region-based methods <ul> <li>MSER(Maximally stable extremal regions)</li> </ul> </li> </ul> </li> <li>Feature Matching <ul> <li>Template matching <ul> <li>Template: 2D matrix centered on point</li> <li>Window를 통해 비교를 하여 matching <ul> <li>SAD: Sum of Absolute Differences</li> <li>SSD: Sum of Squared Differences</li> <li>NCC: Normalized Cross Correlation</li> <li>SSD가 SAD에 비해 outlier에 덜 민감함.</li> </ul> </li> <li>robust하지 않음.</li> </ul> </li> <li>Feature matching <ul> <li>descriptor → matching</li> <li>Discriptor <ul> <li>Feature point에 대한 설명</li> <li>ex) SIFT, ORF, SURF</li> </ul> </li> </ul> </li> </ul> </li> </ul> <h3 id="localization--mapping">Localization &amp; Mapping</h3> <ul> <li>Mapping <ol> <li>feautre extraction &amp; matching</li> <li>back proejection <ol> <li>정확하게 카메라의 ray가 어디서 오는지 모르지만 카메라의 방향은 알기 때문에, 카메라에서 각 점을 이은 선이 한점에서 만나는 점을 찾는다. 해당 점은 실제 feature가 있던 위치.</li> </ol> </li> </ol> </li> <li>Localization <ol> <li>Data association</li> <li>Pose estimation <ol> <li>실제 물체의 position, intrinsic parameter, 2D position을 알면 카메라의 Rotation, Translation을 알 수 있음.</li> </ol> </li> </ol> </li> </ul> <h2 id="11--introduction-to-slam">11. Introduction to SLAM</h2> <h3 id="slam">SLAM</h3> <ul> <li>Simultaneously localization and mapping</li> <li>Given Data <ul> <li>The robot’s controls (로봇 제어)</li> <li>Observation</li> </ul> </li> <li>Wanted <ul> <li>Map of the environment</li> <li>Path of the robot</li> </ul> </li> <li>Probabilistic Approaches’ <ul> <li>Given data 또한 완벽하게 정확하지 않음.</li> <li>따라서 확률 사용.</li> </ul> </li> </ul> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Robot-Programming-lecture-note/Untitled-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Robot-Programming-lecture-note/Untitled-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Robot-Programming-lecture-note/Untitled-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/Robot-Programming-lecture-note/Untitled.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> </figure> <ul> <li>Full SLAM vs Online SLAM <ul> <li>Full SLAM estimates the entire path</li> <li>Online SLAM estimates only the latest pose</li> </ul> </li> <li>Motion model <ul> <li>Described the relative motion of the robot</li> <li>이전 pose 와 control을 알 때, 어떠한 pose를 취하고 있는지</li> <li>Gausian Model, Non-Gaussian Model</li> </ul> </li> <li>Observation mdoel <ul> <li>measurements with the robot’s pose</li> <li>Gaussian Model, Non-Gaussian model</li> </ul> </li> </ul> <h2 id="12-probabilistic-robotics">12. Probabilistic Robotics</h2> <h3 id="marginalization">Marginalization</h3> <ul> <li>원하는 변수는 제외하고 다 더해서 원하는 변수만 남겨 놓는 것.</li> </ul> <h3 id="bayes-formula">Bayes Formula</h3> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Robot-Programming-lecture-note/Untitled%201-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Robot-Programming-lecture-note/Untitled%201-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Robot-Programming-lecture-note/Untitled%201-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/Robot-Programming-lecture-note/Untitled%201.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Robot-Programming-lecture-note/Untitled%202-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Robot-Programming-lecture-note/Untitled%202-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Robot-Programming-lecture-note/Untitled%202-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/Robot-Programming-lecture-note/Untitled%202.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> </figure> </div> </div> <h3 id="causal-vs-diagnostic-reasoning">Causal vs Diagnostic Reasoning</h3> <ul> <li>Diagnostic <ul> <li> <table> <tbody> <tr> <td>P(open</td> <td>z), 즉, 어떤 상황에서 해당 사건이 일어났을 확률</td> </tr> </tbody> </table> </li> </ul> </li> <li>Causal <ul> <li> <table> <tbody> <tr> <td>p(z</td> <td>open), 어떤 사건이 일어났을 때, 어떤 상황인 경우</td> </tr> </tbody> </table> </li> <li>주로 Causal이 얻기 쉬움</li> </ul> </li> </ul> <h3 id="recursive-bayesian-updating">Recursive Bayesian Updating</h3> <ul> <li>Markov assumption <ul> <li>만약 현재 상태가 이전 상태와 독립하다고 가정하고 구함.</li> </ul> </li> </ul> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Robot-Programming-lecture-note/Untitled%203-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Robot-Programming-lecture-note/Untitled%203-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Robot-Programming-lecture-note/Untitled%203-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/Robot-Programming-lecture-note/Untitled%203.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> </figure> <h3 id="action">Action</h3> <ul> <li>Action은 절대로 정확하게 원하는대로 수행되지 않음. 따라서 확률을 이용하여 Action을 취했을 때, 다음 State를 예측. Bay</li> </ul> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Robot-Programming-lecture-note/Untitled%204-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Robot-Programming-lecture-note/Untitled%204-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Robot-Programming-lecture-note/Untitled%204-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/Robot-Programming-lecture-note/Untitled%204.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> </figure> <h3 id="bayes-filter">Bayes Filter</h3> <ul> <li>Given: observation, Sensor model, Action model, Prior state</li> <li>Wanted: Next state</li> </ul> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Robot-Programming-lecture-note/Untitled-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Robot-Programming-lecture-note/Untitled-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Robot-Programming-lecture-note/Untitled-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/Robot-Programming-lecture-note/Untitled.jpeg" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> </figure> <h2 id="13-homogeneous-coordinate">13. Homogeneous Coordinate</h2> <h3 id="homogeneous-coordinates">Homogeneous Coordinates</h3> <ul> <li>a system of coordinates used in projective geometry(Euclidian geometry)</li> <li>Single Matrix can represent affine transformations and projective transformations</li> <li>From Homogeneous to Euclidian Coordinates</li> </ul> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Robot-Programming-lecture-note/Untitled%205-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Robot-Programming-lecture-note/Untitled%205-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Robot-Programming-lecture-note/Untitled%205-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/Robot-Programming-lecture-note/Untitled%205.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> </figure> <h3 id="transformation-and-rotation-matric">Transformation and Rotation Matric</h3> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Robot-Programming-lecture-note/Untitled%206-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Robot-Programming-lecture-note/Untitled%206-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Robot-Programming-lecture-note/Untitled%206-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/Robot-Programming-lecture-note/Untitled%206.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> </div> </div> <ul> <li>Chaining tranformation via matrix <ul> <li>x’ = M1M2x</li> </ul> </li> </ul> <h2 id="14-motion-and-sensor-models">14. Motion and Sensor Models</h2> <h3 id="recursive-bayes-filter">Recursive Bayes Filter</h3> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Robot-Programming-lecture-note/Untitled%207-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Robot-Programming-lecture-note/Untitled%207-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Robot-Programming-lecture-note/Untitled%207-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/Robot-Programming-lecture-note/Untitled%207.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> </figure> <h3 id="prediction-and-correction-step">Prediction and Correction Step</h3> <ul> <li>Prediction step</li> </ul> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Robot-Programming-lecture-note/Untitled%208-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Robot-Programming-lecture-note/Untitled%208-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Robot-Programming-lecture-note/Untitled%208-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/Robot-Programming-lecture-note/Untitled%208.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> </figure> <ul> <li>Correction step</li> </ul> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Robot-Programming-lecture-note/Untitled%209-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Robot-Programming-lecture-note/Untitled%209-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Robot-Programming-lecture-note/Untitled%209-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/Robot-Programming-lecture-note/Untitled%209.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> </figure> <ul> <li>Bayes filter는 recursive state estimation을 위한 framework.</li> <li>다른 방식들을 사용한 다양한 filter들 존재.</li> </ul> <h3 id="motion-model">Motion model</h3> <ul> <li>로봇의 모델은 불명확함.</li> <li>두가지 방식의 motion model 존재 <ul> <li>Odometry-based <ul> <li>wheel encoder가 있는 시스템을 위해 존재</li> <li>wheel encoder? 얼마의 힘을 주면 얼만큼 바퀴가 돌아가는지 계산하는 encoder</li> </ul> </li> <li>Velocity-based <ul> <li>wheel encoder가 없는 system을 위함</li> </ul> </li> <li>두가지 방법 중 Odometry-based가 더 정확.</li> </ul> </li> </ul> <h3 id="odometry-model">Odometry Model</h3> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Robot-Programming-lecture-note/Untitled%2010-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Robot-Programming-lecture-note/Untitled%2010-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Robot-Programming-lecture-note/Untitled%2010-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/Robot-Programming-lecture-note/Untitled%2010.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> </figure> <p>Robot motion</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Robot-Programming-lecture-note/Untitled%2011-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Robot-Programming-lecture-note/Untitled%2011-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Robot-Programming-lecture-note/Untitled%2011-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/Robot-Programming-lecture-note/Untitled%2011.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> </figure> <p>Noise</p> <ul> <li>Calculating the Posterior</li> </ul> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Robot-Programming-lecture-note/Untitled%2012-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Robot-Programming-lecture-note/Untitled%2012-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Robot-Programming-lecture-note/Untitled%2012-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/Robot-Programming-lecture-note/Untitled%2012.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> </figure> <h3 id="velocity-based-model">Velocity-based Model</h3> <ul> <li>Velocity-based Model은 로봇이 원을 그리며 지나간다고 생각을 하고, 이전 위치와 velocity를 이용하여 다음 위치를 구함.</li> </ul> <p>![Screen Shot 2022-12-15 at 12.55.49 AM.png](_posts/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_12.55.49_AM.png” class=”img-fluid rounded z-depth-1” zoomable=true %}</p> <ul> <li>Motion Equation</li> </ul> <p>![Screen Shot 2022-12-15 at 12.56.09 AM.png](_posts/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_12.56.09_AM.png” class=”img-fluid rounded z-depth-1” zoomable=true %}</p> <ul> <li>이때 odometry-based model과는 다르게 로봇 자체의 위치만을 계산하고, 로봇이 바라보는 방향에 대해서는 구하지 않음. heading 정보 없음.</li> <li> <p>따라서 이를 해결하기 위해 추가적인 rotation 정보 더해서 로봇의 heading 세부조정함.</p> <p>![Screen Shot 2022-12-15 at 12.58.59 AM.png](_posts/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_12.58.59_AM.png” class=”img-fluid rounded z-depth-1” zoomable=true %}</p> </li> </ul> <h3 id="sensor-model">Sensor Model</h3> <ul> <li>Sensor로 측정된 값을 통해 observation update</li> </ul> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Robot-Programming-lecture-note/Untitled%2013-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Robot-Programming-lecture-note/Untitled%2013-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Robot-Programming-lecture-note/Untitled%2013-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/Robot-Programming-lecture-note/Untitled%2013.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> </figure> <ul> <li>이때 모델을 통해서 얻은 데이터은 서로 독립적이라고 가정.</li> <li>Model for Laser Scanner</li> </ul> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_2.59.17_AM-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_2.59.17_AM-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_2.59.17_AM-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_2.59.17_AM.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> </figure> <ul> <li>Beam-based Sensor Model</li> </ul> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_2.59.17_AM-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_2.59.17_AM-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_2.59.17_AM-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_2.59.17_AM.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> </figure> <ul> <li>Beam-Endpoint Model <ul> <li>Sensor가 측정한 값을 기준으로 Gaussian blur 처리.</li> <li>이후 각 확률들을 더하기만 하면 되기 때문에 매우 efficient하다.</li> </ul> </li> </ul> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_2.59.05_AM-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_2.59.05_AM-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_2.59.05_AM-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_2.59.05_AM.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> </figure> <ul> <li>Ray-cast Model <ul> <li>Mixture of four models</li> <li>exponential distribution(Reflected by the obstacle) + gaussian distribution(Target) + uniform distribution(For random measurement) + pick distribution (For maximum measurement)</li> <li>Measurement error type <ul> <li>Ray reflected by the obstacles</li> <li>Random measurment</li> <li>Maximum range measurement</li> </ul> </li> </ul> </li> </ul> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_2.58.45_AM-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_2.58.45_AM-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_2.58.45_AM-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_2.58.45_AM.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> </figure> <ul> <li>Perceiving Landmarks with Range-Bearing Sensors</li> </ul> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_2.58.23_AM-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_2.58.23_AM-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_2.58.23_AM-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_2.58.23_AM.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> </figure> <h2 id="15-kalman-filter">15. Kalman Filter</h2> <ul> <li>Linear Gaussian distribution을 사용. <ul> <li>장점 <ul> <li>only need Mean and Variance</li> </ul> </li> </ul> </li> </ul> <h3 id="kalman-filter---1d-case">Kalman Filter - 1D case</h3> <ul> <li>Prediction <ul> <li>Summation of Gaussian distribution</li> </ul> </li> </ul> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_3.06.01_AM-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_3.06.01_AM-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_3.06.01_AM-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_3.06.01_AM.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> </figure> <ul> <li>Update <ul> <li>측정값의 평균, 분산과 예측값의 평균, 분산을 이용하여 최종값 update</li> <li>평균을 구하는 방식은 분산이 더 작은 분포 쪽에 weight을 줄 수 있음.</li> </ul> </li> </ul> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_3.08.17_AM-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_3.08.17_AM-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_3.08.17_AM-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_3.08.17_AM.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> </figure> <ul> <li>Kalman gain <ul> <li>만약 mearsurement is more accurate, K = 1</li> </ul> </li> </ul> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/obot-Programming-lecture-note/Screen_Shot_2022-12-15_at_3.13.39_AM-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/obot-Programming-lecture-note/Screen_Shot_2022-12-15_at_3.13.39_AM-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/obot-Programming-lecture-note/Screen_Shot_2022-12-15_at_3.13.39_AM-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/obot-Programming-lecture-note/Screen_Shot_2022-12-15_at_3.13.39_AM.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> </figure> <h3 id="kalman-filter---multivariate">Kalman filter - Multivariate</h3> <ul> <li>Prediction <ul> <li>1D와 동일한 방식으로 진행.</li> <li>F: state transition matrix from state to state</li> <li>B: state transition matrix from control to state</li> <li>X and U matrix have different dimension → 맞춰줘야함</li> <li>Covariance 사용하여 prediction 진행</li> </ul> </li> </ul> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_3.15.04_AM-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_3.15.04_AM-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_3.15.04_AM-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_3.15.04_AM.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> </figure> <ul> <li>Update <ul> <li>이떼 X는 predicted mean , H는 state transition matrix (using for synchronized dimension)</li> </ul> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_3.25.42_AM-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_3.25.42_AM-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_3.25.42_AM-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_3.25.42_AM.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> </figure> </li> </ul> <p>&lt;/figure&gt;</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;figure&gt;
</code></pre></div></div> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_3.21.46_AM-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_3.21.46_AM-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_3.21.46_AM-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_3.21.46_AM.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> <p>&lt;/figure&gt;</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>- H 삭제. H는 dimension을 맞춰주기 위해 사용한 matrix이기 때문에 삭제 가능.
- 최종
    
    &lt;figure&gt;
</code></pre></div></div> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_3.24.17_AM-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_3.24.17_AM-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_3.24.17_AM-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-15_at_3.24.17_AM.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> <p>&lt;/figure&gt;</p> <h3 id="kalman-filter-assumption">Kalman Filter Assumption</h3> <ul> <li>Kalman filter의 한계 <ul> <li>모든 상황이 linear하다고 가정.</li> <li>따라서 linear하지 않는 상황에서는 사용하지 못함. <ul> <li>Gaussian distribution이 유지가 되지 않음.</li> </ul> </li> </ul> </li> </ul> <h2 id="16-extended-kalman-filter">16. Extended Kalman Filter</h2> <h3 id="kalman-filter-problem">Kalman Filter Problem</h3> <ul> <li>linear하지 상황에서 transformation을 하게 되면, 더이상 Gaussian Distribution이 아니게 된다. 따라서 이를 더이상 mean과 variance만을 이용하여 구할 수 없음.</li> <li>하지만, 대부분 실제 상황에서는 nonlinear한 함수이다. 따라서 Kalman Filter를 사용할 수 없음.</li> <li>이를 해결하기 위해 Local linearization을 사용.</li> </ul> <h3 id="non-linear-transformation">Non-linear transformation</h3> <ul> <li>Non-linear한 상황에서, 특정 부분은, linear transformation으로 approximate할 수 있음.</li> <li> <p>Taylor series를 이용하여 특정 부분을 linearization함.</p> <p>![Screen Shot 2022-12-16 at 5.27.53 PM.png](_posts/Robot-Programming-lecture-note/Screen_Shot_2022-12-16_at_5.27.53_PM.png” class=”img-fluid rounded z-depth-1” zoomable=true %}</p> </li> <li>Non-square matrix에서는 variance를 Jacobian matrix(접면을 나타냄)를 이용.</li> </ul> <h3 id="ekf-linearization---first-order-taylor-expansion">EKF Linearization - First order Taylor Expansion</h3> <ul> <li>Prediction</li> </ul> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-16_at_5.31.43_PM-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-16_at_5.31.43_PM-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-16_at_5.31.43_PM-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-16_at_5.31.43_PM.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> </figure> <ul> <li>Correction</li> </ul> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-16_at_5.32.11_PM-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-16_at_5.32.11_PM-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-16_at_5.32.11_PM-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-16_at_5.32.11_PM.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> </figure> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-16_at_5.34.03_PM-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-16_at_5.34.03_PM-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-16_at_5.34.03_PM-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-16_at_5.34.03_PM.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> </figure> <ul> <li>Kalman Filter vs Extended Kalman Filter</li> </ul> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-16_at_5.38.28_PM-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-16_at_5.38.28_PM-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-16_at_5.38.28_PM-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-16_at_5.38.28_PM.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> </figure> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-16_at_5.38.43_PM-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-16_at_5.38.43_PM-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-16_at_5.38.43_PM-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-16_at_5.38.43_PM.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> </figure> <h2 id="17-ekf-slam">17. EKF SLAM</h2> <h3 id="ekf-slam">EKF SLAM</h3> <ul> <li>State space for the 2D plane constructed with robot’s pose and landmarks</li> </ul> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-16_at_5.46.35_PM-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-16_at_5.46.35_PM-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-16_at_5.46.35_PM-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-16_at_5.46.35_PM.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> </figure> <ul> <li>Mean and Variance</li> </ul> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-16_at_5.47.33_PM-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-16_at_5.47.33_PM-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-16_at_5.47.33_PM-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-16_at_5.47.33_PM.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> </figure> <ul> <li>Filter Cycle <ol> <li>Initialization <ol> <li>Robot은 자신만의 reference frame이 존재 (주로 처음 시작 frame이 reference frame) 이때 모든 Land mark는 모르기 때문에, 0으로 초기화</li> <li> <p>Variance의 경우, 처음 위치는 불확실성이 없어 무조건 0, 반대로 landmark에 대해서는 불확실성이 매우 높기 때문에 무한대로 초기화 해줌(해당 값을 사용하지 않겠다는 뜻)</p> <p>![Screen Shot 2022-12-16 at 5.53.00 PM.png](_posts/Robot-Programming-lecture-note/Screen_Shot_2022-12-16_at_5.53.00_PM.png” class=”img-fluid rounded z-depth-1” zoomable=true %}</p> </li> </ol> </li> <li>State prediction <ol> <li> <p>로봇의 motion이 다음과 같을 때, 이를 2N+3 차원으로 보내주기 위해 차원을 맞춰줌.</p> <p>![Screen Shot 2022-12-16 at 6.00.46 PM.png](_posts/Robot-Programming-lecture-note/Screen_Shot_2022-12-16_at_6.00.46_PM.png” class=”img-fluid rounded z-depth-1” zoomable=true %}</p> </li> <li> <p>Jacobian matrix only affects the robot’s motion. Not the landmarks. 따라서 landmark 부분은 Identity matrix 사용.</p> <p>![Screen Shot 2022-12-16 at 5.54.44 PM.png](_posts/Robot-Programming-lecture-note/Screen_Shot_2022-12-16_at_5.54.44_PM.png” class=”img-fluid rounded z-depth-1” zoomable=true %}</p> <p>![Screen Shot 2022-12-16 at 6.13.54 PM.png](_posts/Robot-Programming-lecture-note/Screen_Shot_2022-12-16_at_6.13.54_PM.png” class=”img-fluid rounded z-depth-1” zoomable=true %}</p> <p>![Screen Shot 2022-12-16 at 6.16.14 PM.png](_posts/Robot-Programming-lecture-note/Screen_Shot_2022-12-16_at_6.16.14_PM.png” class=”img-fluid rounded z-depth-1” zoomable=true %}</p> </li> <li> <p>Prediction 진행</p> <p>![Screen Shot 2022-12-16 at 6.19.04 PM.png](_posts/Robot-Programming-lecture-note/Screen_Shot_2022-12-16_at_6.19.04_PM.png” class=”img-fluid rounded z-depth-1” zoomable=true %}</p> </li> </ol> </li> <li>Measurement prediction <ol> <li> <p>현재 위치를 바탕으로 observation 예측</p> <p>![Screen Shot 2022-12-16 at 6.21.28 PM.png](_posts/Robot-Programming-lecture-note/Screen_Shot_2022-12-16_at_6.21.28_PM.png” class=”img-fluid rounded z-depth-1” zoomable=true %}</p> </li> <li> <p>Jacobian 계산 후 high dimensional space로 이동.</p> <p>![Screen Shot 2022-12-16 at 6.24.14 PM.png](_posts/Robot-Programming-lecture-note/Screen_Shot_2022-12-16_at_6.24.14_PM.png” class=”img-fluid rounded z-depth-1” zoomable=true %}</p> <p>![Screen Shot 2022-12-16 at 6.25.55 PM.png](_posts/Robot-Programming-lecture-note/Screen_Shot_2022-12-16_at_6.25.55_PM.png” class=”img-fluid rounded z-depth-1” zoomable=true %}</p> </li> </ol> </li> <li>Measurement</li> <li>Data association <ol> <li> <p>이후 correction 진행.</p> <p>![Screen Shot 2022-12-16 at 6.27.06 PM.png](_posts/Robot-Programming-lecture-note/Screen_Shot_2022-12-16_at_6.27.06_PM.png” class=”img-fluid rounded z-depth-1” zoomable=true %}</p> </li> </ol> </li> <li>Update</li> </ol> </li> </ul> <h3 id="loop-closing">Loop Closing</h3> <ul> <li>이전에 왔던 공간을 인식하고, error들을 optimize하면서 uncertainty를 줄이는 것.</li> <li>하지만 loop closure가 잘못된 loop을 생성할 수도 있음.</li> </ul> <h3 id="ekf-slam-correlations">EKF SLAM Correlations</h3> <ul> <li>Landmark estimation은 모두 fully correlated 함.</li> <li>Correlation map에서 볼 수 있듯이, 모두 연관되어 있음.</li> </ul> <h3 id="ekf-slam-in-the-limit">EKF SLAM in the Limit</h3> <ul> <li>각 Landmake location의 covariance는 Vehicle location estimation에 결정됨.</li> </ul> <h3 id="ekf-slam-complexity">EKF SLAM Complexity</h3> <ul> <li>Cost per step: O(n^2)</li> <li>Memory consumpotion: O(n^2)</li> </ul> <h2 id="18-particle-filters-and-monte-carlo-localization">18. Particle Filters and Monte Carlo Localization</h2> <h3 id="particle-filter">Particle Filter</h3> <ul> <li>Particle Filter는 이미 Map을 아는 상태에서 진행.</li> <li>Recursive Bayes filter</li> <li>Non-parametric approach</li> <li>Key Idea: Sampling <ul> <li>임의의 분포를 여러개의 samples을 통해 나타낸다.</li> </ul> </li> <li>Particle Set <ul> <li> <p>Set of weighted samples</p> <p>![Screen Shot 2022-12-16 at 8.10.31 PM.png](_posts/Robot-Programming-lecture-note/Screen_Shot_2022-12-16_at_8.10.31_PM.png” class=”img-fluid rounded z-depth-1” zoomable=true %}</p> </li> <li>Rejection Sampling <ul> <li>임의의 값 C 지정 <ul> <li>각 x 마다의 f(x)를 구했을 때 C보다 큰 샘플들만 모았을때 나온 결과는 분산을 대변.</li> </ul> </li> </ul> </li> <li>Importance Sampling Principle <ul> <li>Gaussian distribution의 경우, 다음과 같은 식을 이용하여 분산에 맞는 샘플을 얻을 수 있음. 하지만, 임의의 분산의 경우에는 이러한 식을 구하는 방법이 어려움.</li> <li>이때에는 분산의 차이를 이용하여 진행. 즉, proposal 분산에 대한 sample을 우선 먼저 추출. 이후 각 가중치를 이용하여 해당 샘플이 target 분포와 맞는 sample이 될 수 있도록 한다.</li> </ul> <p>![Screen Shot 2022-12-18 at 1.41.12 AM.png](_posts/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_1.41.12_AM.png” class=”img-fluid rounded z-depth-1” zoomable=true %}</p> </li> </ul> </li> </ul> <h3 id="monte-carlo-localization">Monte Carlo Localization</h3> <ul> <li>위의 Particle Filter를 Motion model에 적용한 것이 Monte Carlo Localization.</li> <li>각 파티클은 Pose hypothesis를 나타냄</li> <li>Particle Filter와 달라진 부분은, 각 sample을 구하는 방식과 weight를 구하는 방식</li> <li>Sample을 구하는 방식은 모션 모델을 이용하여 구함.</li> <li>Weight를 구하는 방식은 observation model을 통해서 구함.</li> </ul> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-17_at_10.22.47_PM-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-17_at_10.22.47_PM-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-17_at_10.22.47_PM-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-17_at_10.22.47_PM.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> </figure> <h3 id="resampling">Resampling</h3> <ul> <li>가장 그럴듯한 샘플들만 남겨 가능성이 적은 Particle은 제거.</li> <li>크게 2가지 방식 존재 <ul> <li>Roulette wheel <ul> <li>각 Weight를 normalize한 후, Binary search를 통해 진행.</li> <li>한번의 1개씩 random하게 particle을 추출한다.</li> <li>따라서 시행할 때마다 다르므로 Variance 큼.</li> <li>O(J log J)</li> </ul> </li> <li>Stochastic universal sampling <ul> <li>Low variance</li> <li>O(J)</li> <li>화살표를 돌리면서 그때마다 화살표에 해당하는 W을 가지고 있는 Particle만 채택</li> </ul> </li> </ul> </li> </ul> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-17_at_10.27.41_PM-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-17_at_10.27.41_PM-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-17_at_10.27.41_PM-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-17_at_10.27.41_PM.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> </figure> <h2 id="19-fast-slam">19. Fast SLAM</h2> <h3 id="dimensionality-problem">Dimensionality Problem</h3> <ul> <li>Particle Filter는 low dimension에서 효과있음.</li> <li>실제 SLAM은 High-dimension</li> <li>따라서 Particle filter를 SLAM에서 사용하기 위해 로봇의 Pose에만 Particle Filter를 적용. Map은 EKF를 사용하여 로봇의 trajectory estimation으로 사용. 즉, 각각의 Particle마다 Map을 예측하고, Observation과 비교하며 진행.</li> </ul> <h3 id="rao-blackwellization">Rao-Blackwellization</h3> <p>![Screen Shot 2022-12-17 at 11.22.33 PM.png](_posts/Robot-Programming-lecture-note/Screen_Shot_2022-12-17_at_11.22.33_PM.png” class=”img-fluid rounded z-depth-1” zoomable=true %}</p> <h3 id="rao-blackwellization-for-slam">Rao-Blackwellization for SLAM</h3> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-17_at_11.23.11_PM-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-17_at_11.23.11_PM-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-17_at_11.23.11_PM-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-17_at_11.23.11_PM.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> </figure> <h3 id="fastslam">FastSLAM</h3> <ul> <li>각각의 Particle은 각각의 Landmark에 대한 EKF를 가지고 있음.</li> </ul> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_1.57.01_AM-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_1.57.01_AM-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_1.57.01_AM-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_1.57.01_AM.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> </figure> <p>Short version</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_1.57.22_AM-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_1.57.22_AM-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_1.57.22_AM-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_1.57.22_AM.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> </figure> <p>Long version</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_1.58.18_AM-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_1.58.18_AM-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_1.58.18_AM-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_1.58.18_AM.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> </figure> <h2 id="20-occupancy-grid-maps">20. Occupancy Grid Maps</h2> <h3 id="logit">Logit</h3> <ul> <li>언제나 확률분포로 변환 가능하게 하는 함수, log(odds)</li> <li>Odds : P/not P</li> </ul> <h3 id="grid-maps">Grid Maps</h3> <ul> <li>Map을 grid로 나누는 것.</li> <li>각 cell은 occupied인지 free space인지 판단.</li> <li>Non-parametric</li> <li>Assumption <ul> <li>The area either free or occupied</li> <li>binary random variable</li> <li>World is static</li> <li>The cells are independent (계산상의 편의를 위해)</li> </ul> </li> <li> <p>Occupancy Probabilities</p> <p>![Screen Shot 2022-12-18 at 12.53.42 AM.png](_posts/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_12.53.42_AM.png” class=”img-fluid rounded z-depth-1” zoomable=true %}</p> <ul> <li> <p>두 확률을 나누면 Odds 계산 가능. Odds와 Binary random variable에서 다음과 같은 성질을 이용하여 P(x) 계산.</p> <p>![Screen Shot 2022-12-18 at 1.09.34 AM.png](_posts/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_1.09.34_AM.png” class=”img-fluid rounded z-depth-1” zoomable=true %}</p> </li> <li> <p>이때 조금 더 효율적인 계산을 위하여 Log Odds notion을 사용.</p> <p>![Screen Shot 2022-12-18 at 1.12.26 AM.png](_posts/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_1.12.26_AM.png” class=”img-fluid rounded z-depth-1” zoomable=true %}</p> </li> <li> <p>즉, inverse sensor model 만 알고 있으면 단순 덧샘으로 log odds를 구할 수 있고 이를 이용하여 마지막에 아래의 식을 통해 p(x)를 구할 수 있음.</p> </li> </ul> <p>![Screen Shot 2022-12-18 at 1.11.07 AM.png](_posts/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_1.11.07_AM.png” class=”img-fluid rounded z-depth-1” zoomable=true %}</p> </li> <li>Inverse Sensor Model <ul> <li>로봇의 위치와 센서 관측값이 있을 때 각 cell의 occupied 되어 있을 확률이다. 여기서는 2가지 모델을 예를 보여준다. <ul> <li>Sonar Sensor model <ul> <li>Sonar sensor는 상대적으로 거리 측정값에 대한 noise가 큼.</li> <li>Sonar센서는 측정값의 noise가 크기 때문에 <em>d</em>가 상대적으로 크다.</li> </ul> </li> <li>Laser Range Finder(LiDAR sensor) <ul> <li>Lidar는 sonar에 비해 거리측정 오차가 매우 적다. 따라서 occupied로 생각하는 영역이 sonar모델에 비해 매우 좁다.4</li> </ul> </li> </ul> </li> </ul> </li> </ul> <p>Sonar Sensor</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_1.21.55_AM-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_1.21.55_AM-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_1.21.55_AM-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_1.21.55_AM.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> </figure> <p>Laser Range Finder</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_1.22.49_AM-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_1.22.49_AM-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_1.22.49_AM-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_1.22.49_AM.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> </figure> <h2 id="22-visual-slam">22. Visual SLAM</h2> <h3 id="building-and-tracking-a-map">Building and Tracking a map</h3> <ul> <li>Building</li> <li>Tracking <ul> <li>Point correspondences를 통해 pose 구함.</li> </ul> </li> </ul> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_2.23.44_AM-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_2.23.44_AM-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_2.23.44_AM-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_2.23.44_AM.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> </figure> <h3 id="component-of-visual-slam">Component of Visual SLAM</h3> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_2.20.14_AM-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_2.20.14_AM-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_2.20.14_AM-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_2.20.14_AM.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> </figure> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_2.20.50_AM-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_2.20.50_AM-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_2.20.50_AM-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_2.20.50_AM.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> </figure> <ul> <li>Short-term tracking <ul> <li>Pose estimation given the map</li> <li>Keyframe proposals</li> </ul> </li> <li>Long-term tracking <ul> <li>Visual place recognition</li> <li>Loop closure detection over keyframes</li> </ul> </li> <li>Mapping <ul> <li>Building and optimizing the map over keyfrrames</li> <li>Data fusion</li> </ul> </li> </ul> <h3 id="local-features">Local Features</h3> <ul> <li>주변과 다르게 특징이 되는 이미지 feature</li> <li>Saliency, Locality</li> </ul> <h3 id="feature-detection">Feature detection</h3> <ul> <li>Corners, Blob regions</li> <li>Conrner <ul> <li>모든 방향에서 변화가 일어남.</li> <li> <p>Gradient를 이용하여 Corner 찾음.</p> <p>![Screen Shot 2022-12-18 at 2.03.23 AM.png](_posts/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_2.03.23_AM.png” class=”img-fluid rounded z-depth-1” zoomable=true %}</p> </li> <li>이때 H는</li> </ul> </li> <li>Blob detecter <ul> <li>LoG(Laplacian of Gaussian) <ul> <li>엣지부분에서 위아래 변화. 일정 부분 이하로 두 엣지 사이가 가까워지면 (blob) 값 중첩되어 커짐., 블록의 크기 정해져있음. 동일 커널로 이미지 크기 다양하게 하여 찾음.</li> <li>이미지에 blob이 많고, 해당 kernel 에 걸리는 blob을 찾고싶을 때 kernel 고정</li> <li>반대의경우에는 kernel을 여러개 사용하거나, 아님 이미지의 크기를 여러개 사용하여 kernel을 여러개 사용하는 방식과 동일하게 사용할 수 있도록 함</li> </ul> </li> <li>DOG <ul> <li>가우시안의 차를 이용하여 계산(SIFT에서 사용)</li> <li>이미지 blur 4번 한 것이 이미지 크기를 줄인 것과 동일. 따라서 이미지를 줄여서 사용. → 계산량 감소</li> </ul> </li> </ul> </li> <li>Point detector <ul> <li>FAST <ul> <li>가운데 점을 중심으로 원을 16개 점 → 연속해서 12개의 점이 밝을 경우 코너로 정의.</li> </ul> </li> </ul> </li> </ul> <h3 id="feature-descriptor">Feature descriptor</h3> <ul> <li>Template: N*N image patch를 이용, Descriptor: 주로 Vetor를 이용하여 표현.</li> <li>Template matching <ul> <li>SAD <ul> <li> <p>difference 값이 작을수로 matching. (절대값)</p> <p>![Screen Shot 2022-12-18 at 2.13.48 AM.png](_posts/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_2.13.48_AM.png” class=”img-fluid rounded z-depth-1” zoomable=true %}</p> </li> </ul> </li> <li>SSD <ul> <li> <p>SAD와 동일, L2 norm (outlier에 더 강함)</p> <p>![Screen Shot 2022-12-18 at 2.13.57 AM.png](_posts/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_2.13.57_AM.png” class=”img-fluid rounded z-depth-1” zoomable=true %}</p> </li> </ul> </li> <li>NCC <ul> <li>밝기값이 바뀌어도 동일한 feature임을 인식하기 위해 Normalization 진행.</li> <li> <p>maximum 값 = 1</p> <p>![Screen Shot 2022-12-18 at 2.14.23 AM.png](_posts/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_2.14.23_AM.png” class=”img-fluid rounded z-depth-1” zoomable=true %}</p> </li> </ul> </li> </ul> </li> <li>Descriptor <ul> <li>HOG <ul> <li>각 픽셀이 위와 아래의 gradient를 비교하여 gradient vector값 구함. 회전에 취약함.</li> <li>Dominant orientation을 기준으로 각 히스토그램의 값을 미뤄서 rotation맞춤.</li> </ul> </li> <li>SIFT (Orientation assignment) <ul> <li>HOG와 비슷하게 grandient vector를 구한 후, 4*4 window에 8개의 direction으로 vector 합쳐줌.</li> <li> <p>pick point를 기준으로 돌림. 이후 HOG와 비슷하게 gradient vector 구함. tree 형식으로 매칭.</p> <p>![Screen Shot 2022-12-18 at 2.18.27 AM.png](_posts/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_2.18.27_AM.png” class=”img-fluid rounded z-depth-1” zoomable=true %}</p> </li> </ul> </li> <li>BRIEF <ul> <li>binary 값 사용. matching: Hamming distance 사용.</li> <li>다른 값의 개수를 찾으면 되기 때문에, XOR 사용하여 빠르게 matching할 수 있음.</li> <li>픽셀 페어값의 순서 항상 동일해야됨. rotation에 매우 취약.</li> </ul> </li> <li>ORB <ul> <li>Fast, BRIEF 두가지 방식을 모두 차용하여 수행.</li> <li>처음 detection때 orient값까지 함께 주함. Gradient 값으로 전체 patch의 rotation값을 구함.</li> <li>이미지를 돌려준 다음에 BRIEF 사용.</li> </ul> </li> </ul> </li> </ul> <h2 id="23-orb-slam">23. ORB SLAM</h2> <h3 id="system-structure">System structure</h3> <ul> <li>tracking <ul> <li>localization of camera</li> <li>Selecting new keyframe</li> </ul> </li> <li>Local mapping <ul> <li>Keyframe process</li> <li>Local BA</li> <li>Culling redundant Keyframes</li> </ul> </li> <li>Loop closing <ul> <li>Searching loops for every Keyframes</li> <li>Pose graph optimization</li> </ul> </li> </ul> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_2.27.43_AM-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_2.27.43_AM-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_2.27.43_AM-1400.webp"></source> <p style="text-align:center;"> <img src="/assets/img/Robot-Programming-lecture-note/Screen_Shot_2022-12-18_at_2.27.43_AM.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"></p> </picture> </figure> <h3 id="prerequisite">Prerequisite</h3> <ul> <li>Covisibility graph <ul> <li>각 keyframe들이 edge로 연결되어 있는 그래프.</li> <li>각 edge의 weight은 각 Keyframe에서 겹치는 Key point들을 나타냄.</li> </ul> </li> <li>Essantial graph <ul> <li>Minimal spanning tree (최소신장트리) 가장 연결이 많이 되는 Keyframe들만 사용.</li> </ul> </li> <li>Bag of words <ul> <li>code → clustered descriptor (dimension을 나눌 때 cluster 되어있는 부분)</li> <li>code book → 각 code를 histogram으로 표현.</li> <li>즉 해당 scen에 대한 descriptor</li> </ul> </li> <li>Perspective n Point <ul> <li>n : 2D to 3D일때 사용된 점의 개수</li> <li>2D를 넣으면 3D pose 나옴. (translation &amp; rotation)</li> <li>Camera coordinate 에 대한 World coordinate (지정 좌표계)</li> </ul> </li> <li>Bundle Adjustment <ul> <li>pixel → world point 구한후, 이를 다시 projection하여 최적화.</li> <li>intrinsic parameter , pose, point 보정</li> </ul> </li> </ul> <h3 id="place-recognition">Place Recognition</h3> <ul> <li>Visual vocabulary와 Recognition Database (Codebooks of keyframes)를 이용하여 Place recognition 진행.</li> </ul> <h3 id="tracking">Tracking</h3> <ul> <li>Feature extraction <ul> <li>256 bit descriptor</li> <li>Harris corner로 candidate pixel extract, 이것들로 진행</li> </ul> </li> <li>Pose estimation <ul> <li>Homography → 평면간의 matrix</li> <li>Fundamental Matrix → 3D planar scene matrix</li> </ul> </li> <li>Relocalization</li> <li>Track Local Map <ul> <li>pose에 대해서만 bundle adjustment 진행.</li> </ul> </li> <li>New Keyframe Decision</li> </ul> <h3 id="local-mapping">Local Mapping</h3> <ul> <li>Recent Map Point Clustering</li> <li>New Map Point creation</li> <li>Local BA: 3D map, pose 둘다 adjustment 진행 전체를 하는것이 아닌 주변 연결된 몇개의 keyframe 간의 optimize 진행.</li> <li>Local keyframe culling: keyframe culling 진행. (90% map points are visible in 3 other keyframes)</li> </ul> <h3 id="loop-closing-1">Loop Closing</h3> <ul> <li>Loop Detection</li> <li>Loop Correction</li> </ul> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Jueun Mun. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>